{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At a high level, we'll go about web scraping through this process:\n",
    "1. Manually explore the site in a web browser, and identify the relevant HTML elements.\n",
    "2. Use the requests module to obtain the HTML from the page.\n",
    "3. Use BeautifulSoup to parse the HTML and obtain the text/data that we want.\n",
    "4. (Maybe) Script the process of requesting another page and parsing the data from it as well.\n",
    "5. Take this data further down the data science pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "1. Import the get() function from the requests module, BeautifulSoup from bs4, and pandas.\n",
    "2. Assign the address of the web page to a variable named url.\n",
    "3. Request the server the content of the web page by using get(), and store the server’s response in the variable response.\n",
    "4. Print the response text to ensure you have an html page.\n",
    "5. Take a look at the actual web page contents and inspect the source to understand the structure a bit.\n",
    "6. Use BeautifulSoup to parse the HTML into a variable ('soup').\n",
    "7. Identify the key tags you need to extract the data you are looking for.\n",
    "8. Create a dataframe of the data desired.\n",
    "9. Run some summary stats and inspect the data to ensure you have what you wanted.\n",
    "10. Edit the data structure as needed, especially so that one column has all the text you want included in this analysis.\n",
    "11. Create a corpus of the column with the text you want to analyze.\n",
    "12. Store that corpus for use in a future notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codeup Blog Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://codeup.com/codeups-data-science-career-accelerator-is-here/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Data Science'} # Some websites don't accept the pyhon-requests default user-agent\n",
    "response = get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making the request, we'll perform a quick sanity check to make sure what we are looking at is indeed HTML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en-US\"><head >\t<meta charset=\"UTF-8\" />\n",
      "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "\t<meta name='robots' content='index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1' />\n",
      "<style type=\"text/css\" id=\"nab-alternative-loader-style\"></style>\n",
      "<script type=\"text/javascript\" id=\"nelio-ab-testing-kickoff\">/*nelio-ab-testing-kick\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the beautiful soup library to work with HTML data in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a soup variable holding the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see also `soup.find_all`\n",
    "#\n",
    "# beautiful soup uses `class_` as the keyword argument for searching\n",
    "# for a class because `class` is a reserved word in python\n",
    "# we'll use the class name that we identified from looking in the inspector in chrome\n",
    "article = soup.find('div', class_='jupiterx-post-content')\n",
    "article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some text to process, we can store it for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article.txt', 'w') as f:\n",
    "    f.write(article.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now package all of our code up in a nice function that we can use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text():\n",
    "    # if we already have the data, read it locally\n",
    "    if os.path.exists('article.txt'):\n",
    "        with open('article.txt') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # otherwise go fetch the data\n",
    "    url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    article = soup.find('div', class_='jupiterx-post-content')\n",
    "\n",
    "    # save it for next time\n",
    "    with open('article.txt', 'w') as f:\n",
    "        f.write(article.text)\n",
    "\n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/', \n",
    "           'https://codeup.com/data-science-myths/',\n",
    "           'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "           'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "           'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_content(url):\n",
    "    '''\n",
    "    This function will take in a single url as a string, create an empty dictionary. It will return a dictionary with the 'title' of the article, and 'content' of the article.\n",
    "    '''\n",
    "    # create empty dictionary\n",
    "    blog_dict = {}\n",
    "    \n",
    "    # the header tells the website who is pulling the data\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "    \n",
    "    # response is 'get'ting the data from the website\n",
    "    response = get(url, headers=headers)\n",
    "    \n",
    "    # make that delicious Campbells (return the text)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    # give me the entire content as text\n",
    "    content = soup.find('div', class_='jupiterx-post-content')\n",
    "    \n",
    "    # give me the title as text\n",
    "    title = soup.find('h1', class_='jupiterx-post-title')\n",
    "    \n",
    "    # add title and content to dictionary\n",
    "    blog_dict = {'title': title.text,\n",
    "                'content': content.text}\n",
    "\n",
    "    return blog_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles(url_list):\n",
    "    '''\n",
    "    This function takes in a list of URLs from the Codeup blog, and returns a dictionary of each articles 'title' and content'\n",
    "    '''\n",
    "    \n",
    "    # create an empty ist\n",
    "    list_of_blogs = []\n",
    "    \n",
    "    # cycle through each url in the list\n",
    "    for url in url_list:\n",
    "        # call on the 'get_title_content' function to create a dictionary for each url\n",
    "        # append each dictionary\n",
    "        list_of_blogs.append(get_title_content(url))\n",
    "        \n",
    "    return list_of_blogs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Codeup’s Data Science Career Accelerator is Here!',\n",
       "  'content': 'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'},\n",
       " {'title': 'Data Science Myths',\n",
       "  'content': 'By Dimitri Antoniou and Maggie Giust\\nData Science, Big Data, Machine Learning, NLP, Neural Networks…these buzzwords have rapidly spread into mainstream use over the last few years. Unfortunately, definitions are varied and sources of truth are limited. Data Scientists are in fact not magical unicorn wizards who can snap their fingers and turn a business around! Today, we’ll take a cue from our favorite Mythbusters to tackle some common myths and misconceptions in the field of Data Science.\\n\\xa0\\nMyth #1: Data Science = Statistics\\nAt first glance, this one doesn’t sound unreasonable. Statistics is defined as, “A branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data.” That sounds a lot like our definition of Data Science: a method of drawing actionable intelligence from data. \\nIn truth, statistics is actually one small piece of Data Science. As our Senior Data Scientist puts it, “Statistics forces us to make assumptions about the nature of the relationship between variables, the distribution of the data, etc.” In the traditional Data Science venn diagram, you’ll see that math/stats make up ⅓ of a working professional. These are tools and skills to leverage, but data science itself is about drawing intelligence from data.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #2: Data Scientist = Business/Data Analyst\\nThis one is so common that we wrote a whole post about it! These are separate and different roles within the data field. While a data scientist will often do analytics, their spectrum of work is wider. A data analyst will use structured data to create dashboards and KPIs, while a Data Scientist deals with unstructured and messy data for a range of outputs. If they’re interested, business analysts will often progress to data scientists.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #3: Data Science = Data Science\\nThis one’s tricky, because it’s impossible to either confirm or bust! The ‘myth’ is that one person or company using the term Data Science is not necessarily the same as another person or company using the same term. Depending on organizational capacity, individual experience, educational background, and many other variables, we might be using the same name for different animals.\\nTl;dr: don’t assume a common understanding across hiring managers, recruiters, and practitioners. Look instead for specifics of tools, techniques, methodologies, and outputs. That being said, this one falls in the “plausible” category, because it may actually be true in some circumstances, while false in others.\\nPLAUSIBLE\\n\\nvia GIPHY\\n\\xa0\\nMyth #4: Data Science curricula are well-defined and consistent.\\nWe recommend checking this one out for yourself! A quick google search for bootcamps, master’s degree programs, and online courses will reveal that different organizations teach different things. There is no commonly accepted framework for teaching data science! Some focus more on the engineering, others focus more on machine learning, some think deep learning is foundational, and some prefer to use R. \\nOur curriculum was built through employer interviews, practitioner interviews, market research, and company partnerships. But we’re based in Texas! A bootcamp in New York might follow the same process and end up with a different syllabus. Keep in mind, whatever your learning path, that there will be gaps in your learning. The most important thing is to recognize those gaps.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #5: If I want to be a data scientist, I just need to learn Python or R.\\nThis one is common and dangerous! Just like statistics, programming languages like Python and R are tools. They’re just pieces of a larger puzzle! Knowing Python without understanding the data science pipeline is like knowing how to build a floor without having a floor plan. Of course, these are valuable technical skills that give you a leg up, but they’re second in importance to asking the right questions, knowing what tools to use when, and communicating your findings.\\nBUSTED\\n\\nvia GIPHY\\nStill have questions? Reach out to us! We’re always here to help.\\n\\n'},\n",
       " {'title': 'Data Science VS Data Analytics: What’s The Difference?',\n",
       "  'content': 'By Dimitri Antoniou\\nA week ago, Codeup launched our immersive Data Science career accelerator! With our first-class kicking off in February and only 25 seats available, we’ve been answering a lot of questions from prospective students. One, in particular, has come up so many times we decided to dedicate a blog post to it. What is the difference between data science and data analytics?\\nFirst, let’s define some of our terms! Take a look at this blog to understand what Data Science is. In short, it is a method of turning raw data into action, leading to the desired outcome. Big Data refers to data sets that are large and complex, usually exceeding the capacity of computers and normal processing power to deal with. Machine Learning is the process of ‘learning’ underlying patterns of data in order to automate the extraction of intelligence from that data.\\n\\xa0\\n\\xa0\\nNow, let’s look at the data pipeline that data scientists work through to reach the actionable insights and outcomes we mentioned:\\n\\nWe start by collecting data, which may come from social media channels, network logs, financials, employee records, or more.\\nWe then process that data into usable information stored in databases or streamed.\\nNext, we look back on the history of that data to summarize, describe, and explain, turning the data into meaningful knowledge. Here we’re primarily using mathematics, statistics, and visualization methods.\\nNow we convert that knowledge into intelligence, seeking to predict future events so that we can make decisions in the present. This is where practitioners will introduce mathematical/statistical modeling through machine learning to their data.\\nFinally, we enable action by building automations, running tests, building visualizations, monitoring new data, etc.\\n\\nData professionals work at different stages of the spectrum to move data through the pipeline. On the left, Big Data Engineers specialize in collecting, storing, and processing data, getting it from Data to Information. In the middle, analysts work to understand and convert that information to knowledge. Lastly, a Machine Learning Engineer utilizes machine learning algorithms to turn intelligence into action by building automations, visualizations, recommendations, and predictions.\\nData Scientists span multiple stages of this pipeline, from information to action. They will spend about 70% of their time wrangling data in the information stage. They will conduct a statistical analysis to derive knowledge. Lastly, they predict future events and build automations using machine learning.\\nFor those technical folk out there, data science is to data engineering or machine learning engineering as full-stack development is to front-end or back-end development. For the non-technical folk, data science is the umbrella term that houses data analytics, machine learning, and other data professions.\\nSo what’s the biggest difference between a data analyst and a data scientist? Data scientists utilize computer programming and machine learning in addition to mathematics and statistics. \\nStill have questions? Reach out to us.\\xa0Wondering which of Codeup’s programs is right for you? We’ve got you covered. And of course, if data science gets you excited, get started with us today!\\n\\n'},\n",
       " {'title': '10 Tips to Crush It at the SA Tech Job Fair',\n",
       "  'content': 'SA Tech Job Fair\\nThe third bi-annual San Antonio Tech Job Fair is just around the corner. Over 25 companies will be at The Jack Guenther Pavilion\\xa0on April 10th, and they are hungry for new tech team members!\\nAt the job fair, companies want to quickly source a list of new talent leads. AKA they need to find qualified employees they can begin interviewing for jobs. Recruiters will represent their organization at tables with informational handouts and company swag. Your goal at a job fair is to set yourself apart from other candidates and ensure your name makes it to the top of those lead lists.\\nThink of your interaction with the company as a mini screening interview. The company rep will subtly evaluate basic qualities like your professionalism, communication and interpersonal skills, work experience, and interest level in the organization. Job fairs are also an opportunity for you to gain information about companies that may not be easily accessible online. \\xa0\\nAt Codeup, we’re passionate about bridging the gap between talent and demand, so we’ve outlined 10 tips to ensure you bring your A-game and leave a lasting impression!\\n10 Tips for Totally Crushing it at the SA Tech Job Fair\\n\\nUse keywords to describe your skills, but don’t go overboard. You’ll probably be talking to a recruiter or talent acquisition specialist. As a technical candidate, recognize these individuals usually aren’t developers or network administrators. They know terms like “JavaScript” and “Apache,” but haven’t written a line of code or spun up a server, so don’t get too caught up in industry jargon.\\nResearch the companies ahead of time. Review the list of attending companies and make sure you know what the company does and whether or not they hire people in your desired role. Look up recent news on the company and mention it during your conversation.\\nDefine your own goals for the job fair. Are you searching for a specific type of role or company culture? What matters most in your job search? Are there companies you want to prioritize? \\xa0Develop a game plan and be intentional with your time.\\nPrepare a stellar résumé. Bring about 20 copies of your résumé to the event, printed on nice paper. We won’t cover resume writing in this post, but there are a plethora of online resources you can consult. For job fairs, don’t worry about cover letters.\\nPolish your online profiles. If recruiters have a copy of your resume, you can be sure they will stalk you online soon. Make sure your online presence is professional and appropriate. A good place to start is by Googling yourself. Update your LinkedIn, and clean up any social media profiles.\\nCraft a 30-60 second elevator pitch. You may only have a few minutes with an employer. What will you say if they ask, “Tell me about yourself?” Consider structuring your pitch like this: Who you are + What you do + What your goals are + Why that matters to the company.\\nDon’t show up in a t-shirt, but trade in your suit for something more chill. Always keep it professional, but remember: tech is typically more casual than other industries. You’ll likely feel out of place if you look like you belong on Wall St., so refer to this guide on dressing for tech interviews.\\nDon’t forget the basics. Start and end each conversation with a firm handshake. Make eye contact while conversing. Smile! Thank the recruiter before you move on to the next table.\\nAsk educated questions. Don’t waste valuable face time with recruiters by asking questions like, “What does [Insert Company here] do?” They hate that question! Instead, try some of these:\\n\\nWhat are the top 3-5 examples of knowledge, skills, and abilities you look for in candidates?\\nWhat’s the best advice you have for someone who wants to work here?\\nWhat is your interview process like?\\nAre you hiring for any roles not currently listed on your websites?\\n\\n\\nFollow up. Collect business cards from each table. The next day, send a short note expressing your interest in the company’s opportunities and thanking the recruiter for his or her time.\\n\\nRSVP for the SA Tech Job Fair taking place at the Jack Guenther Pavilion – September 18th starting at 4 pm.\\xa0\\n\\n'},\n",
       " {'title': 'Competitor Bootcamps Are Closing. Is the Model in Danger?',\n",
       "  'content': 'Competitor Bootcamps Are Closing. Is the Model in Danger?\\n\\xa0\\n\\nIs the programming bootcamp model in danger?\\nIn recent news, DevBootcamp and The Iron Yard announced that they are closing their doors. This is big news. DevBootcamp was the first programming bootcamp model and The Iron Yard is a national player with 15 campuses across the U.S. In both cases, the companies cited an unsustainable business model. Does that mean the boot-camp model is dead?\\n\\ntl;dr “Nope!”\\nBootcamps exist because traditional education models have failed to provide students job-ready skills for the 21st century. Students demand better employment options from their education. Employers demand skilled and job ready candidates. Big Education’s failure to meet those needs through traditional methods created the fertile ground for the new business model of the programming bootcamp.\\nEducation giant Kaplan and Apollo Education Group (owner of University of Phoenix) bought their way into this new educational model when they purchased The Iron Yard and DevBootcamp. They purchased their competition with the intent to scale up the model. Unfortunately, Big Education is too habituated to coming up short for students. They bought the upstarts that challenged them, tried making changes to run those bootcamps in the “Big Education” way, and, sadly, they’ve closed the doors when they realized that scaling education is more challenging when student outcomes truly matter.\\nThe bootcamp model is still new and there will be plenty consolidation, competition, and changes in the future. This model is based on actually being adaptive, innovative, and sustainable. And there’s always room for innovation.\\n\\n\\nWhat we’ve learned at Codeup…\\n\\n\\nEducation is challenging to scale.\\nPrioritizing quality over growth pays off.\\n\\nWhat we’re doing at Codeup…\\n\\nHigher standards in our application process are leading to better student outcomes.\\nOur reputation and commitment to quality is opening new doors to previously uninterested/unreachable employers.\\nIn the beginning, the majority of Codeup graduates went to work with startups and small businesses. We’re now seeing a larger amount of our graduates place at medium to large sized businesses.\\nDemand is growing and employers are learning that the results are in the graduates.\\nCodeup’s model is sustainable, inclusive, and works.\\n\\nCall or contact us today to see how Codeup’s commitment to quality and approach to being a career accelerator can make a profound difference in your life.\\n\\n'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_blog_articles(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "- Write a function that scrapes the news articles for the following topics:\n",
    "    - Business\n",
    "    - Sports\n",
    "    - Technology\n",
    "    - Entertainment\n",
    "\n",
    "- The end product of this should be a function named get_news_articles that returns a list of dictionaries, where each dictionary has this shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'title': 'The article title',\n",
    "#     'content': 'The article content',\n",
    "#     'category': 'business' # for example\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints:\n",
    "- Start by inspecting the website in your browser. Figure out which elements will be useful.\n",
    "- Start by creating a function that handles a single article and produces a dictionary like the one above.\n",
    "- Next create a function that will find all the articles on a single page and call the function you created in the last step for every article on the page.\n",
    "- Now create a function that will use the previous two functions to scrape the articles from all the pages that you need, and do any additional processing that needs to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of news articles\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base url for all articles\n",
    "base_url = 'https://inshorts.com/en/read/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish variable for first cat in cats\n",
    "first_cat = categories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for the first category\n",
    "first_page = base_url + first_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first page: https://inshorts.com/en/read/business\n",
      "headers: {'User-Agent': 'Codeup Data Science'}\n"
     ]
    }
   ],
   "source": [
    "# let's check our work so far...\n",
    "print(f'first page: {first_page}')\n",
    "print(f'headers: {headers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step one: get our content\n",
    "response = get(first_page, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html lang=\"en\">\\n\\n<head>\\n  <meta charset=\"utf-8\" />\\n  <style>\\n    /* The Modal (background) */\\n    .modal_contact {\\n        display: none; /* Hidden by default */\\n        position: fixed; /* Stay in place */\\n        z-index: 8; /* Sit on top */\\n        left: 0;\\n        top: 0;\\n        width: 100%; /* Full width */\\n        height: 100%;\\n        overflow: auto; /* Enable scroll if ne'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did it work?\n",
    "response.text[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our soup\n",
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are we doing here?????????????????????\n",
    "articles = soup.select('.news-card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"news-card z-depth-1\" itemscope=\"\" itemtype=\"http://schema.org/NewsArticle\">\n",
       "<span content=\"\" itemid=\"https://inshorts.com/en/news/chinas-exteacher-turned-billionaire-no-more-a-billionaire-as-shares-fall-98-1627290782038\" itemprop=\"mainEntityOfPage\" itemscope=\"\" itemtype=\"https://schema.org/WebPage\"></span>\n",
       "<span itemprop=\"author\" itemscope=\"itemscope\" itemtype=\"https://schema.org/Person\">\n",
       "<span content=\"Pragya Swastik\" itemprop=\"name\"></span>\n",
       "</span>\n",
       "<span content=\"China's ex-teacher turned billionaire no more a billionaire as shares fall 98%\" itemprop=\"description\"></span>\n",
       "<span itemprop=\"image\" itemscope=\"\" itemtype=\"https://schema.org/ImageObject\">\n",
       "<meta content=\"https://static.inshorts.com/inshorts/images/v1/variants/jpg/m/2021/07_jul/26_mon/img_1627289502940_772.jpg?\" itemprop=\"url\"/>\n",
       "<meta content=\"864\" itemprop=\"width\"/>\n",
       "<meta content=\"483\" itemprop=\"height\"/>\n",
       "</span>\n",
       "<span itemprop=\"publisher\" itemscope=\"itemscope\" itemtype=\"https://schema.org/Organization\">\n",
       "<span content=\"https://inshorts.com/\" itemprop=\"url\"></span>\n",
       "<span content=\"Inshorts\" itemprop=\"name\"></span>\n",
       "<span itemprop=\"logo\" itemscope=\"\" itemtype=\"https://schema.org/ImageObject\">\n",
       "<span content=\"https://assets.inshorts.com/inshorts/images/v1/variants/jpg/m/2018/11_nov/21_wed/img_1542823931298_497.jpg\" itemprop=\"url\"></span>\n",
       "<meta content=\"400\" itemprop=\"width\"/>\n",
       "<meta content=\"60\" itemprop=\"height\"/>\n",
       "</span>\n",
       "</span>\n",
       "<div class=\"news-card-image\" style=\"background-image: url('https://static.inshorts.com/inshorts/images/v1/variants/jpg/m/2021/07_jul/26_mon/img_1627289502940_772.jpg?')\">\n",
       "</div>\n",
       "<div class=\"news-card-title news-right-box\">\n",
       "<a class=\"clickable\" href=\"/en/news/chinas-exteacher-turned-billionaire-no-more-a-billionaire-as-shares-fall-98-1627290782038\" onclick=\"track_GA_Mixpanel({'hitType': 'event', 'category': 'TitleOfNews', 'action': 'clicked', 'label': 'China's%20ex-teacher%20turned%20billionaire%20no%20more%20a%20billionaire%20as%20shares%20fall%2098%25)' });\" style=\"color:#44444d!important\">\n",
       "<span itemprop=\"headline\">China's ex-teacher turned billionaire no more a billionaire as shares fall 98%</span>\n",
       "</a>\n",
       "<div class=\"news-card-author-time news-card-author-time-in-title\">\n",
       "<a href=\"/prev/en/news/chinas-exteacher-turned-billionaire-no-more-a-billionaire-as-shares-fall-98-1627290782038\"><span class=\"short\">short</span></a> by <span class=\"author\">Pragya Swastik</span> / \n",
       "      <span class=\"time\" content=\"2021-07-26T09:13:02.000Z\" itemprop=\"datePublished\">02:43 pm</span> on <span clas=\"date\">26 Jul 2021,Monday</span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"news-card-content news-right-box\">\n",
       "<div itemprop=\"articleBody\">China's Larry Chen, a former teacher who became a billionaire with edtech company Gaotu Techedu, lost his billionaire status after his company's shares fell 98%. Chen, Gaotu Techedu's Founder and CEO, is now worth $336 million according to Bloomberg. The development comes as China's new regulations banned companies teaching school curriculums from making profits, raising capital or going public.</div>\n",
       "<div class=\"news-card-author-time news-card-author-time-in-content\">\n",
       "<a href=\"/prev/en/news/chinas-exteacher-turned-billionaire-no-more-a-billionaire-as-shares-fall-98-1627290782038\"><span class=\"short\">short</span></a> by <span class=\"author\">Pragya Swastik</span> / \n",
       "      <span class=\"time\" content=\"2021-07-26T09:13:02.000Z\" itemprop=\"dateModified\">02:43 pm</span> on <span class=\"date\">26 Jul</span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"news-card-footer news-right-box\">\n",
       "<div class=\"read-more\">read more at <a class=\"source\" href=\"https://www.bloombergquint.com/markets/chinese-education-tycoon-loses-15-billion-as-shares-plunge-98?utm_campaign=fullarticle&amp;utm_medium=referral&amp;utm_source=inshorts \" onclick=\"track_GA_Mixpanel({'hitType': 'event', 'category': 'ReadMore', 'action': 'clicked', 'label': 'BloombergQuint' });\" target=\"_blank\">BloombergQuint</a></div>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does the first article look like?\n",
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div itemprop=\"articleBody\">A new job posting by Amazon has fuelled speculations that the e-commerce major may begin accepting Bitcoin, Ether and other cryptocurrencies as a form of payment. According to the job posting, Amazon's Payments Acceptance &amp; Experience team is hiring a 'Digital Currency and Blockchain Product Lead'. Following the speculations around Amazon's plan, Bitcoin surged near $40,000 on Monday.</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are we doing here???????????????????????????\n",
    "articles[1].select(\"[itemprop='articleBody']\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(article, category):\n",
    "    '''\n",
    "    This function takes in a single article and category, and returns a dictionary with the\n",
    "    article 'title', 'content', and 'category'.\n",
    "    '''\n",
    "    # Attribute selector (grabbing the title)\n",
    "    title = article.select(\"[itemprop='headline']\")[0].text\n",
    "    \n",
    "    # article body (grabbing the content)\n",
    "    content = article.select(\"[itemprop='articleBody']\")[0].text\n",
    "    \n",
    "    # create the empty dictionary\n",
    "    output = {}\n",
    "    \n",
    "    # add each variable to the dictionary\n",
    "    output[\"title\"] = title\n",
    "    output[\"content\"] = content\n",
    "    output[\"category\"] = category\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(category, base =\"https://inshorts.com/en/read/\"):\n",
    "    \"\"\"\n",
    "    This function takes in a category as a string. Category must be an available category in inshorts\n",
    "    Returns a list of dictionaries where each dictionary represents a single inshort article\n",
    "    \"\"\"\n",
    "    \n",
    "    # We concatenate our base_url with the category\n",
    "    url = base + category\n",
    "    \n",
    "    # Set the headers\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "\n",
    "    # Get the http response object from the server\n",
    "    response = get(url, headers=headers)\n",
    "\n",
    "    # Make soup out of the raw html\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    # Ignore everything, focusing only on the news cards\n",
    "    articles = soup.select(\".news-card\")\n",
    "    \n",
    "    # create an empty list\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through every article tag/soup \n",
    "    for article in articles:\n",
    "        \n",
    "        # Returns a dictionary of the article's title, body, and category\n",
    "        article_data = get_article(article, category) \n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        output.append(article_data)\n",
    "    \n",
    "    # Return the list of dictionaries\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news_articles(categories):\n",
    "    \"\"\"\n",
    "    Takes in a list of categories where the category is part of the URL pattern on inshorts\n",
    "    Returns a dataframe of every article from every category listed\n",
    "    Each row in the dataframe is a single article\n",
    "    \"\"\"\n",
    "    # Create a list for all inshorts articles\n",
    "    all_inshorts = []\n",
    "    \n",
    "    # loop through each category\n",
    "    for category in categories:\n",
    "        # grab each article from a particular category\n",
    "        all_category_articles = get_articles(category)\n",
    "        # add each list of articles/category to the all_inshorts list\n",
    "        all_inshorts = all_inshorts + all_category_articles\n",
    "\n",
    "    # make it a dataframe\n",
    "    df = pd.DataFrame(all_inshorts)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
