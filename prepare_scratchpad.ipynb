{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Scratchpad for Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "- The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "- In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's establish some original text to build our function on\n",
    "original = \"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed \\\n",
    "a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), \\\n",
    "but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\"\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdős and george pólya are influential hungarian mathematicians who contributed a lot to the field. erdős's name contains the hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as erdos or erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase all letters in the text\n",
    "\n",
    "article = original.lower()\n",
    "\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field. erdos's name contains the hungarian letter 'o' ('o' with double acute accent), but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizaton: Remove inconsistencies in unicode charater encoding.\n",
    "# encode the strings into ASCII byte-strings (ignore non-ASCII characters)\n",
    "# decode the byte-string back into a string\n",
    "\n",
    "article = unicodedata.normalize('NFKD', article)\\\n",
    ".encode('ascii', 'ignore')\\\n",
    ".decode('utf-8')\n",
    "\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos's name contains the hungarian letter 'o' 'o' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "\n",
    "article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(original):\n",
    "    '''\n",
    "    This funtion will take in a single string, \n",
    "    - lowercase all of the characters, \n",
    "    - normalize unicode characters, \n",
    "    - replace anything that is not a letter/number/whitespace/single quote.\n",
    "    '''\n",
    "    \n",
    "    #lowercase all letters in the text\n",
    "    article = original.lower()\n",
    "    \n",
    "    # Normalizaton: Remove inconsistencies in unicode charater encoding.\n",
    "    # encode the strings into ASCII byte-strings (ignore non-ASCII characters)\n",
    "    # decode the byte-string back into a string\n",
    "    article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8')\n",
    "    \n",
    "    # remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "    article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_article = basic_clean(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the tokenizer\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "# Use the tokenizer\n",
    "article = tokenizer.tokenize(article, return_str = True)\n",
    "\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prepped_article):\n",
    "    '''\n",
    "    This function takes in the result of my basic_clean function (a single, cleaned string) and tokenizes all the words in the string.\n",
    "    It returns the tokenized string as a list\n",
    "    '''\n",
    "    \n",
    "    # Create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "    # Use the tokenizer\n",
    "    tokenized_article = tokenizer.tokenize(prepped_article)\n",
    "    \n",
    "    return tokenized_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_article = tokenize(prepped_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(tokenized_article):\n",
    "    '''\n",
    "    This function will take in a single string, perform a PorterStemmer, and return the stemmed string.\n",
    "        \n",
    "    *** This function is set up to run AFTER using the 'tokenize' function. ***\n",
    "    If the 'tokenize' function has not been called, then we need to use a .split() in the for loop.\n",
    "    '''\n",
    "    \n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Apply the stemmer to each word in our string.\n",
    "    stems = [ps.stem(word) for word in tokenized_article] # Need to add .split() after tokenized_article if tokenization has not occured\n",
    "    \n",
    "    article_stemmed = ' '.join(stems)\n",
    "\n",
    "    \n",
    "    return article_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdo and georg polya are influenti hungarian mathematician who contribut a lot to the field erdo ' s name contain the hungarian letter ' o ' ' o ' with doubl acut accent but is often incorrectli written as erdo or erdo either by mistak or out of typograph necess\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(tokenized_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/thxmanu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I need to download 'wordnet'\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokenized_article):\n",
    "    '''\n",
    "    This function will take in a single string, perform lemmatization, and return the lemmatized string.\n",
    "    \n",
    "    *** This function is set up to run AFTER using the 'tokenize' function. ***\n",
    "    If the 'tokenize' function has not been called, then we need to use a .split() in the for loop.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Create the Lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of tokenized words.\n",
    "    lemmas = [wnl.lemmatize(word) for word in tokenized_article] # Need to add .split() after tokenized_article if tokenization has not occured\n",
    "    \n",
    "    \n",
    "    # Join our list of words into a string again; assign to a variable to save changes.\n",
    "    article_lemmatized = ' '.join(lemmas)\n",
    "    \n",
    "    return article_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "please_work = lemmatize(tokenized_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematician who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written a erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "please_work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "- This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's build the base function, then let's add in the additional arguments\n",
    "\n",
    "def remove_stopwords(input_string, extra_words=None, exclude_words=None):\n",
    "    '''\n",
    "    This function will take in a single string ('input_string') that has already been prepped, remove all stop words, and return the string minus the stopwords.\n",
    "    - [extra_words] = list of additional words to add to stopword_list; default=None\n",
    "    - [exclude_words] = list of words to remove from stopword_list, and leave in 'output_string'; default=None\n",
    "    - each list must be defined outside of the function\n",
    "    - *** if 'input_string' has not been lemmatized, will need to do so before function can run properly.\n",
    "    '''\n",
    "    \n",
    "    # lemmatize if necessary\n",
    "#     words = lemmatize(input_string).split()\n",
    "\n",
    "    # if 'input_string' already lemmatized,\n",
    "    words = input_string.split()\n",
    "    \n",
    "    # define stopwords\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    if extra_words == None:\n",
    "        stopword_list = stopword_list\n",
    "        \n",
    "    else:\n",
    "        for word in extra_words:\n",
    "            stopword_list.append(word)\n",
    "            \n",
    "    if exclude_words == None:\n",
    "        stopword_list = stopword_list\n",
    "    else:\n",
    "        for word in exclude_words:\n",
    "            stopword_list.remove(word)\n",
    "        \n",
    "    # create a list of words from my string with stopwords removed\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # join words in list back into strings\n",
    "    article_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['influential', 'mathematician']\n",
    "keep = ['i', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematician who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written a erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "please_work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of news articles\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = acquire.get_all_news_articles(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon job posting fuels speculations about pl...</td>\n",
       "      <td>A new job posting by Amazon has fuelled specul...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China's ex-teacher turned billionaire no more ...</td>\n",
       "      <td>China's Larry Chen, a former teacher who becam...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk takes a jibe at rival car companies, says...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahua Moitra writes to FM to look into 'over-i...</td>\n",
       "      <td>Lok Sabha MP Mahua Moitra has shared a letter ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment rate rises in both urban, rural a...</td>\n",
       "      <td>India's unemployment rate soared to 7.14% in t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>US offers further air support to Afghan troops...</td>\n",
       "      <td>The US will continue to carry out airstrikes a...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Afghan Army chief postpones India visit amid T...</td>\n",
       "      <td>Afghan Army chief General Wali Mohammad Ahmadz...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>46 Afghan soldiers flee to Pakistan in retreat...</td>\n",
       "      <td>The Pakistani Army on Monday said that 46 Afgh...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>New Zealand agrees to accept alleged Islamic S...</td>\n",
       "      <td>New Zealand on Monday agreed to repatriate an ...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Ugandan govt spends $30 mn on cars for lawmake...</td>\n",
       "      <td>The Ugandan government was criticised after it...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Amazon job posting fuels speculations about pl...   \n",
       "1    China's ex-teacher turned billionaire no more ...   \n",
       "2    Musk takes a jibe at rival car companies, says...   \n",
       "3    Mahua Moitra writes to FM to look into 'over-i...   \n",
       "4    Unemployment rate rises in both urban, rural a...   \n",
       "..                                                 ...   \n",
       "142  US offers further air support to Afghan troops...   \n",
       "143  Afghan Army chief postpones India visit amid T...   \n",
       "144  46 Afghan soldiers flee to Pakistan in retreat...   \n",
       "145  New Zealand agrees to accept alleged Islamic S...   \n",
       "146  Ugandan govt spends $30 mn on cars for lawmake...   \n",
       "\n",
       "                                               content  category  \n",
       "0    A new job posting by Amazon has fuelled specul...  business  \n",
       "1    China's Larry Chen, a former teacher who becam...  business  \n",
       "2    Tesla CEO and the world's second-richest perso...  business  \n",
       "3    Lok Sabha MP Mahua Moitra has shared a letter ...  business  \n",
       "4    India's unemployment rate soared to 7.14% in t...  business  \n",
       "..                                                 ...       ...  \n",
       "142  The US will continue to carry out airstrikes a...     world  \n",
       "143  Afghan Army chief General Wali Mohammad Ahmadz...     world  \n",
       "144  The Pakistani Army on Monday said that 46 Afgh...     world  \n",
       "145  New Zealand on Monday agreed to repatriate an ...     world  \n",
       "146  The Ugandan government was criticised after it...     world  \n",
       "\n",
       "[147 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/', \n",
    "           'https://codeup.com/data-science-myths/',\n",
    "           'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "           'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "           'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = acquire.get_blog_articles(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = pd.DataFrame(codeup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Articles\n",
    "- [x] title to hold the title\n",
    "- [x] original to hold the original article/post content\n",
    "- [x] clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- [x] stemmed to hold the stemmed version of the cleaned data.\n",
    "- [] lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon job posting fuels speculations about pl...</td>\n",
       "      <td>A new job posting by Amazon has fuelled specul...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China's ex-teacher turned billionaire no more ...</td>\n",
       "      <td>China's Larry Chen, a former teacher who becam...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk takes a jibe at rival car companies, says...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahua Moitra writes to FM to look into 'over-i...</td>\n",
       "      <td>Lok Sabha MP Mahua Moitra has shared a letter ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment rate rises in both urban, rural a...</td>\n",
       "      <td>India's unemployment rate soared to 7.14% in t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>US offers further air support to Afghan troops...</td>\n",
       "      <td>The US will continue to carry out airstrikes a...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Afghan Army chief postpones India visit amid T...</td>\n",
       "      <td>Afghan Army chief General Wali Mohammad Ahmadz...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>46 Afghan soldiers flee to Pakistan in retreat...</td>\n",
       "      <td>The Pakistani Army on Monday said that 46 Afgh...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>New Zealand agrees to accept alleged Islamic S...</td>\n",
       "      <td>New Zealand on Monday agreed to repatriate an ...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Ugandan govt spends $30 mn on cars for lawmake...</td>\n",
       "      <td>The Ugandan government was criticised after it...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Amazon job posting fuels speculations about pl...   \n",
       "1    China's ex-teacher turned billionaire no more ...   \n",
       "2    Musk takes a jibe at rival car companies, says...   \n",
       "3    Mahua Moitra writes to FM to look into 'over-i...   \n",
       "4    Unemployment rate rises in both urban, rural a...   \n",
       "..                                                 ...   \n",
       "142  US offers further air support to Afghan troops...   \n",
       "143  Afghan Army chief postpones India visit amid T...   \n",
       "144  46 Afghan soldiers flee to Pakistan in retreat...   \n",
       "145  New Zealand agrees to accept alleged Islamic S...   \n",
       "146  Ugandan govt spends $30 mn on cars for lawmake...   \n",
       "\n",
       "                                               content  category  \n",
       "0    A new job posting by Amazon has fuelled specul...  business  \n",
       "1    China's Larry Chen, a former teacher who becam...  business  \n",
       "2    Tesla CEO and the world's second-richest perso...  business  \n",
       "3    Lok Sabha MP Mahua Moitra has shared a letter ...  business  \n",
       "4    India's unemployment rate soared to 7.14% in t...  business  \n",
       "..                                                 ...       ...  \n",
       "142  The US will continue to carry out airstrikes a...     world  \n",
       "143  Afghan Army chief General Wali Mohammad Ahmadz...     world  \n",
       "144  The Pakistani Army on Monday said that 46 Afgh...     world  \n",
       "145  New Zealand on Monday agreed to repatriate an ...     world  \n",
       "146  The Ugandan government was criticised after it...     world  \n",
       "\n",
       "[147 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what it looks like...\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_norm_list(df, target):\n",
    "    '''\n",
    "    This function takes in a pandas DataFrame, and a target variable column. \n",
    "    It returns a list of the target variable that has been normalized.\n",
    "    '''\n",
    "\n",
    "    norm_list = []\n",
    "    for i in df[target]:\n",
    "        norm_list.append(basic_clean(i))\n",
    "    \n",
    "    return norm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_norm_list(df, target):\n",
    "    '''\n",
    "    This function takes in a pandas DataFrame, and a target variable column, normalizes it, and tokenizes it.\n",
    "    It returns a list of the target variable that has been normalized, and tokenized.\n",
    "    '''\n",
    "    norm_list = create_norm_list(df=df, target=target)\n",
    "    norm_token_list = []\n",
    "    for i in norm_list:\n",
    "        norm_token_list.append(tokenize(i))\n",
    "        \n",
    "    return norm_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_stop_remove(input_string):\n",
    "    '''\n",
    " \n",
    "    '''\n",
    "    \n",
    "    # define stopwords\n",
    "    stopword_list = stopwords.words('english')\n",
    "        \n",
    "    # create a list of words from my string with stopwords removed\n",
    "    filtered_words = [word for word in input_string if word not in stopword_list]\n",
    "    \n",
    "    # join words in list back into strings\n",
    "    without_stops = ' '.join(filtered_words)\n",
    "    \n",
    "    return without_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_col(df, target):\n",
    "    '''\n",
    "    This function takes in a pandas DataFrame, and a target variable column. \n",
    "    It calls upon my create_norm_list, and token_norm_list functions to first normalize, then tokenize the target variable.\n",
    "    It then removes stop words, and creates a new column in the DataFrame. Returns a pandas DataFrame.\n",
    "    '''\n",
    "    norm_token_list = token_norm_list(df, target)\n",
    "    \n",
    "    norm_tok_stop_list = []\n",
    "    for i in norm_token_list:\n",
    "        norm_tok_stop_list.append(easy_stop_remove(i))\n",
    "    \n",
    "#     df[f'{target}_normalized'] = norm_tok_stop_list\n",
    "    \n",
    "    return norm_tok_stop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_col(df, target):\n",
    "    norm_tok_stop_list = normalize_col(df, target)\n",
    "    \n",
    "    stem_list = []\n",
    "    for i in norm_tok_stop_list:\n",
    "        stem_list.append(stem(i))\n",
    "        \n",
    "    df[f'{target}_stemmed'] = stem_list\n",
    "    \n",
    "    return stem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_col(df, target):\n",
    "    norm_tok_stop_list = normalize_col(df, target)\n",
    "    \n",
    "    lem_list = []\n",
    "    for i in norm_tok_stop_list:\n",
    "        lem_list.append(lemmatize(i))\n",
    "        \n",
    "    df[f'{target}_lemmatized'] = lem_list\n",
    "    \n",
    "    return lem_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_the_cols(df, target):\n",
    "    df[f'{target}_normalized'] = normalize_col(df, target)\n",
    "    df[f'{target}_stemmed'] = stem_col(df, target)\n",
    "    df[f'{target}_lemmatized'] = lem_col(df, target)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>content_normalized</th>\n",
       "      <th>content_stemmed</th>\n",
       "      <th>content_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon job posting fuels speculations about pl...</td>\n",
       "      <td>A new job posting by Amazon has fuelled specul...</td>\n",
       "      <td>business</td>\n",
       "      <td>new job posting amazon fuelled speculations ec...</td>\n",
       "      <td>n e w   j o b   p o s t i n g   a m a z o n   ...</td>\n",
       "      <td>n e w   j o b   p o s t i n g   a m a z o n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China's ex-teacher turned billionaire no more ...</td>\n",
       "      <td>China's Larry Chen, a former teacher who becam...</td>\n",
       "      <td>business</td>\n",
       "      <td>china ' larry chen former teacher became billi...</td>\n",
       "      <td>c h i n a   '   l a r r y   c h e n   f o r m ...</td>\n",
       "      <td>c h i n a   '   l a r r y   c h e n   f o r m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk takes a jibe at rival car companies, says...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "      <td>tesla ceo world ' secondrichest person elon mu...</td>\n",
       "      <td>t e s l a   c e o   w o r l d   '   s e c o n ...</td>\n",
       "      <td>t e s l a   c e o   w o r l d   '   s e c o n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahua Moitra writes to FM to look into 'over-i...</td>\n",
       "      <td>Lok Sabha MP Mahua Moitra has shared a letter ...</td>\n",
       "      <td>business</td>\n",
       "      <td>lok sabha mp mahua moitra shared letter wrote ...</td>\n",
       "      <td>l o k   s a b h a   m p   m a h u a   m o i t ...</td>\n",
       "      <td>l o k   s a b h a   m p   m a h u a   m o i t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unemployment rate rises in both urban, rural a...</td>\n",
       "      <td>India's unemployment rate soared to 7.14% in t...</td>\n",
       "      <td>business</td>\n",
       "      <td>india ' unemployment rate soared 714 week endi...</td>\n",
       "      <td>i n d i a   '   u n e m p l o y m e n t   r a ...</td>\n",
       "      <td>i n d i a   '   u n e m p l o y m e n t   r a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>US offers further air support to Afghan troops...</td>\n",
       "      <td>The US will continue to carry out airstrikes a...</td>\n",
       "      <td>world</td>\n",
       "      <td>us continue carry airstrikes taliban support a...</td>\n",
       "      <td>u s   c o n t i n u e   c a r r y   a i r s t ...</td>\n",
       "      <td>u s   c o n t i n u e   c a r r y   a i r s t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Afghan Army chief postpones India visit amid T...</td>\n",
       "      <td>Afghan Army chief General Wali Mohammad Ahmadz...</td>\n",
       "      <td>world</td>\n",
       "      <td>afghan army chief general wali mohammad ahmadz...</td>\n",
       "      <td>a f g h a n   a r m y   c h i e f   g e n e r ...</td>\n",
       "      <td>a f g h a n   a r m y   c h i e f   g e n e r ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>46 Afghan soldiers flee to Pakistan in retreat...</td>\n",
       "      <td>The Pakistani Army on Monday said that 46 Afgh...</td>\n",
       "      <td>world</td>\n",
       "      <td>pakistani army monday said 46 afghan soldiers ...</td>\n",
       "      <td>p a k i s t a n i   a r m y   m o n d a y   s ...</td>\n",
       "      <td>p a k i s t a n i   a r m y   m o n d a y   s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>New Zealand agrees to accept alleged Islamic S...</td>\n",
       "      <td>New Zealand on Monday agreed to repatriate an ...</td>\n",
       "      <td>world</td>\n",
       "      <td>new zealand monday agreed repatriate alleged i...</td>\n",
       "      <td>n e w   z e a l a n d   m o n d a y   a g r e ...</td>\n",
       "      <td>n e w   z e a l a n d   m o n d a y   a g r e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Ugandan govt spends $30 mn on cars for lawmake...</td>\n",
       "      <td>The Ugandan government was criticised after it...</td>\n",
       "      <td>world</td>\n",
       "      <td>ugandan government criticised spent 302 millio...</td>\n",
       "      <td>u g a n d a n   g o v e r n m e n t   c r i t ...</td>\n",
       "      <td>u g a n d a n   g o v e r n m e n t   c r i t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Amazon job posting fuels speculations about pl...   \n",
       "1    China's ex-teacher turned billionaire no more ...   \n",
       "2    Musk takes a jibe at rival car companies, says...   \n",
       "3    Mahua Moitra writes to FM to look into 'over-i...   \n",
       "4    Unemployment rate rises in both urban, rural a...   \n",
       "..                                                 ...   \n",
       "142  US offers further air support to Afghan troops...   \n",
       "143  Afghan Army chief postpones India visit amid T...   \n",
       "144  46 Afghan soldiers flee to Pakistan in retreat...   \n",
       "145  New Zealand agrees to accept alleged Islamic S...   \n",
       "146  Ugandan govt spends $30 mn on cars for lawmake...   \n",
       "\n",
       "                                               content  category  \\\n",
       "0    A new job posting by Amazon has fuelled specul...  business   \n",
       "1    China's Larry Chen, a former teacher who becam...  business   \n",
       "2    Tesla CEO and the world's second-richest perso...  business   \n",
       "3    Lok Sabha MP Mahua Moitra has shared a letter ...  business   \n",
       "4    India's unemployment rate soared to 7.14% in t...  business   \n",
       "..                                                 ...       ...   \n",
       "142  The US will continue to carry out airstrikes a...     world   \n",
       "143  Afghan Army chief General Wali Mohammad Ahmadz...     world   \n",
       "144  The Pakistani Army on Monday said that 46 Afgh...     world   \n",
       "145  New Zealand on Monday agreed to repatriate an ...     world   \n",
       "146  The Ugandan government was criticised after it...     world   \n",
       "\n",
       "                                    content_normalized  \\\n",
       "0    new job posting amazon fuelled speculations ec...   \n",
       "1    china ' larry chen former teacher became billi...   \n",
       "2    tesla ceo world ' secondrichest person elon mu...   \n",
       "3    lok sabha mp mahua moitra shared letter wrote ...   \n",
       "4    india ' unemployment rate soared 714 week endi...   \n",
       "..                                                 ...   \n",
       "142  us continue carry airstrikes taliban support a...   \n",
       "143  afghan army chief general wali mohammad ahmadz...   \n",
       "144  pakistani army monday said 46 afghan soldiers ...   \n",
       "145  new zealand monday agreed repatriate alleged i...   \n",
       "146  ugandan government criticised spent 302 millio...   \n",
       "\n",
       "                                       content_stemmed  \\\n",
       "0    n e w   j o b   p o s t i n g   a m a z o n   ...   \n",
       "1    c h i n a   '   l a r r y   c h e n   f o r m ...   \n",
       "2    t e s l a   c e o   w o r l d   '   s e c o n ...   \n",
       "3    l o k   s a b h a   m p   m a h u a   m o i t ...   \n",
       "4    i n d i a   '   u n e m p l o y m e n t   r a ...   \n",
       "..                                                 ...   \n",
       "142  u s   c o n t i n u e   c a r r y   a i r s t ...   \n",
       "143  a f g h a n   a r m y   c h i e f   g e n e r ...   \n",
       "144  p a k i s t a n i   a r m y   m o n d a y   s ...   \n",
       "145  n e w   z e a l a n d   m o n d a y   a g r e ...   \n",
       "146  u g a n d a n   g o v e r n m e n t   c r i t ...   \n",
       "\n",
       "                                    content_lemmatized  \n",
       "0    n e w   j o b   p o s t i n g   a m a z o n   ...  \n",
       "1    c h i n a   '   l a r r y   c h e n   f o r m ...  \n",
       "2    t e s l a   c e o   w o r l d   '   s e c o n ...  \n",
       "3    l o k   s a b h a   m p   m a h u a   m o i t ...  \n",
       "4    i n d i a   '   u n e m p l o y m e n t   r a ...  \n",
       "..                                                 ...  \n",
       "142  u s   c o n t i n u e   c a r r y   a i r s t ...  \n",
       "143  a f g h a n   a r m y   c h i e f   g e n e r ...  \n",
       "144  p a k i s t a n i   a r m y   m o n d a y   s ...  \n",
       "145  n e w   z e a l a n d   m o n d a y   a g r e ...  \n",
       "146  u g a n d a n   g o v e r n m e n t   c r i t ...  \n",
       "\n",
       "[147 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_the_cols(news_df, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
